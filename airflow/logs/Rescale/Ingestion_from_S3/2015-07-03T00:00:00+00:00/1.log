[2019-02-10 19:45:06,266] {models.py:1359} INFO - Dependencies all met for <TaskInstance: Rescale.Ingestion_from_S3 2015-07-03T00:00:00+00:00 [queued]>
[2019-02-10 19:45:06,267] {models.py:1359} INFO - Dependencies all met for <TaskInstance: Rescale.Ingestion_from_S3 2015-07-03T00:00:00+00:00 [queued]>
[2019-02-10 19:45:06,268] {models.py:1571} INFO - 
--------------------------------------------------------------------------------
Starting attempt 1 of 2
--------------------------------------------------------------------------------

[2019-02-10 19:45:06,277] {models.py:1593} INFO - Executing <Task(BashOperator): Ingestion_from_S3> on 2015-07-03T00:00:00+00:00
[2019-02-10 19:45:06,277] {base_task_runner.py:118} INFO - Running: ['bash', '-c', 'airflow run Rescale Ingestion_from_S3 2015-07-03T00:00:00+00:00 --job_id 117 --raw -sd DAGS_FOLDER/rs-pipeline1.py --cfg_path /tmp/tmp6vcdfwxq']
[2019-02-10 19:45:07,189] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3 [2019-02-10 19:45:07,189] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-02-10 19:45:07,473] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3 [2019-02-10 19:45:07,473] {models.py:273} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags/rs-pipeline1.py
[2019-02-10 19:45:07,489] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3 [2019-02-10 19:45:07,489] {cli.py:520} INFO - Running <TaskInstance: Rescale.Ingestion_from_S3 2015-07-03T00:00:00+00:00 [running]> on host ip-172-31-15-235.us-east-2.compute.internal
[2019-02-10 19:45:07,502] {bash_operator.py:77} INFO - Tmp dir root location: 
 /tmp
[2019-02-10 19:45:07,502] {bash_operator.py:86} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=Rescale
AIRFLOW_CTX_TASK_ID=Ingestion_from_S3
AIRFLOW_CTX_EXECUTION_DATE=2015-07-03T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2015-07-03T00:00:00+00:00
[2019-02-10 19:45:07,503] {bash_operator.py:100} INFO - Temporary script location: /tmp/airflowtmpahgy7s3f/Ingestion_from_S3iqofg008
[2019-02-10 19:45:07,503] {bash_operator.py:110} INFO - Running command: python /home/ec2-user/get_s3data.py
[2019-02-10 19:45:07,511] {bash_operator.py:119} INFO - Output:
[2019-02-10 19:45:09,536] {bash_operator.py:123} INFO - Downloading the file spotprices_20181216_604329154527_us-east-1.csv
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO - Traceback (most recent call last):
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO -   File "/home/ec2-user/get_s3data.py", line 30, in <module>
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO -     my_bucket.download_file(object.key, d_dir+"/"+filename)
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO -   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/boto3/s3/inject.py", line 246, in bucket_download_file
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO -     ExtraArgs=ExtraArgs, Callback=Callback, Config=Config)
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO -   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/boto3/s3/inject.py", line 172, in download_file
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO -     extra_args=ExtraArgs, callback=Callback)
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO -   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/boto3/s3/transfer.py", line 305, in download_file
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO -     bucket, key, filename, extra_args, subscribers)
[2019-02-10 19:45:09,552] {bash_operator.py:123} INFO -   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/s3transfer/manager.py", line 345, in download
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -     call_args, DownloadSubmissionTask, extra_main_kwargs)
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/s3transfer/manager.py", line 461, in _submit_transfer
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -     main_kwargs=main_kwargs
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/s3transfer/futures.py", line 467, in submit
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -     future = ExecutorFuture(self._executor.submit(task))
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -   File "/home/ec2-user/anaconda3/lib/python3.7/concurrent/futures/thread.py", line 160, in submit
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -     self._adjust_thread_count()
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -   File "/home/ec2-user/anaconda3/lib/python3.7/concurrent/futures/thread.py", line 181, in _adjust_thread_count
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -     t.start()
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -   File "/home/ec2-user/anaconda3/lib/python3.7/threading.py", line 847, in start
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO -     _start_new_thread(self._bootstrap, ())
[2019-02-10 19:45:09,553] {bash_operator.py:123} INFO - RuntimeError: can't start new thread
[2019-02-10 19:45:09,846] {bash_operator.py:127} INFO - Command exited with return code 1
[2019-02-10 19:45:09,870] {models.py:1788} ERROR - Bash command failed
Traceback (most recent call last):
  File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/airflow/models.py", line 1657, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/airflow/operators/bash_operator.py", line 131, in execute
    raise AirflowException("Bash command failed")
airflow.exceptions.AirflowException: Bash command failed
[2019-02-10 19:45:09,876] {models.py:1811} INFO - Marking task as UP_FOR_RETRY
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3 Traceback (most recent call last):
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3   File "/home/ec2-user/airflow/venv/bin/airflow", line 32, in <module>
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3     args.func(args)
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/airflow/utils/cli.py", line 74, in wrapper
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3     return f(*args, **kwargs)
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/airflow/bin/cli.py", line 526, in run
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3     _run(args, dag, ti)
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/airflow/bin/cli.py", line 445, in _run
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3     pool=args.pool,
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/airflow/utils/db.py", line 73, in wrapper
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3     return func(*args, **kwargs)
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/airflow/models.py", line 1657, in _run_raw_task
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3     result = task_copy.execute(context=context)
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3   File "/home/ec2-user/airflow/venv/lib/python3.7/site-packages/airflow/operators/bash_operator.py", line 131, in execute
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3     raise AirflowException("Bash command failed")
[2019-02-10 19:45:09,904] {base_task_runner.py:101} INFO - Job 117: Subtask Ingestion_from_S3 airflow.exceptions.AirflowException: Bash command failed
[2019-02-10 19:45:11,279] {logging_mixin.py:95} INFO - [2019-02-10 19:45:11,278] {jobs.py:2527} INFO - Task exited with return code 1
